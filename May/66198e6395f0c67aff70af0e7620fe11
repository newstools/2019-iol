Facial-recognition systems have in recent years been used in thousands of law-enforcement investigations across the US as a way to quickly identify a person of interest. The systems are designed to match two similar photographs: typically a photo of someone caught on camera, and a corresponding photo in an official database. But a new review by Georgetown Law’s Centre on Privacy and Technology found that police have used the systems in a number of questionable ways. Some investigators edited the photos in the hope of revealing more matches, including swopping out facial features, blurring or combining parts of photos, and pasting-in images of other people's lips or eyes. In one case, New York police detectives believed a suspect looked like the actor Woody Harrelson, so they ran the actor's image through a search, then arrested a man the system had suggested might be a match. The uses of distorted images, centre researcher Clare Garvie said, boosted the chances that authorities would arrest and prosecute an innocent person. Sergeant Jessica McRorie, a spokesperson for the New York police, said the agency “had been deliberate and responsible in its use of facial recognition technology” and that officers seek probable cause or other evidence to support the AI tool’s findings, adding: “No one has ever been arrested on the basis of a facial recognition match alone.” The research, based on interviews and documents released by the agencies through public-records requests, found the NYPD’s facial-recognition search tool had been used preceding more than 2800 arrests in the past five years, and had been used roughly 8000 times last year. “Officers need to clearly understand just how unreliable facial-recognition matches are,” Garvie said. Yet “people are being arrested solely on the basis of this type of use. We need to pump the brakes and make sure we're not allowing fundamental violations of people’s rights.” - The Washington Post